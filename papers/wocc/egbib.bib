@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{ramjee2019fast,
  title={Fast deep learning for automatic modulation classification},
  author={Ramjee, Sharan and Ju, Shengtai and Yang, Diyu and Liu, Xiaoyu and Gamal, Aly El and Eldar, Yonina C},
  journal={arXiv preprint arXiv:1901.05850},
  year={2019}
}

@inproceedings{hong2017automatic,
  title={Automatic modulation classification using recurrent neural networks},
  author={Hong, Dehua and Zhang, Zilong and Xu, Xiaodong},
  booktitle={2017 3rd IEEE International Conference on Computer and Communications (ICCC)},
  pages={695--700},
  year={2017},
  organization={IEEE}
}

@ARTICLE{8454504,
  author={Meng, Fan and Chen, Peng and Wu, Lenan and Wang, Xianbin},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Automatic Modulation Classification: A Deep Learning Enabled Approach}, 
  year={2018},
  volume={67},
  number={11},
  pages={10760-10772},
  keywords={Modulation;Feature extraction;Signal to noise ratio;Training;Machine learning;Receivers;Convolution;Automatic modulation classification;convolution neural network;deep learning;two-step training},
  doi={10.1109/TVT.2018.2868698}}

@article{peng2018modulation,
  title={Modulation classification based on signal constellation diagrams and deep learning},
  author={Peng, Shengliang and Jiang, Hanyu and Wang, Huaxia and Alwageed, Hathal and Zhou, Yu and Sebdani, Marjan Mazrouei and Yao, Yu-Dong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={3},
  pages={718--727},
  year={2018},
  publisher={IEEE}
}

@article{dobre2007survey,
  title={Survey of automatic modulation classification techniques: classical approaches and new trends},
  author={Dobre, Octavia A and Abdi, Ali and Bar-Ness, Yeheskel and Su, Wei},
  journal={IET communications},
  volume={1},
  number={2},
  pages={137--156},
  year={2007},
  publisher={IET}
}

@article{dao2023vt,
  title={VT-MCNet: High-Accuracy Automatic Modulation Classification Model based on Vision Transformer},
  author={Dao, Thien-Thanh and Noh, Dae-Il and Hasegawa, Mikio and Sekiya, Hiroo and Pham, Quoc-Viet and Hwang, Won-Joo},
  journal={IEEE Communications Letters},
  year={2023},
  publisher={IEEE}
}


@inproceedings{hamidi2021mcformer,
  title={Mcformer: A transformer based deep neural network for automatic modulation classification},
  author={Hamidi-Rad, Shahab and Jain, Swayambhoo},
  booktitle={2021 IEEE Global Communications Conference (GLOBECOM)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@article{qu2024enhancing,
  title={Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction},
  author={Qu, Yunpeng and Lu, Zhilin and Zeng, Rui and Wang, Jintao and Wang, Jian},
  journal={arXiv preprint arXiv:2401.01056},
  year={2024}
}
@inproceedings{peng2017modulation,
  title={Modulation classification using convolutional neural network based deep learning model},
  author={Peng, Shengliang and Jiang, Hanyu and Wang, Huaxia and Alwageed, Hathal and Yao, Yu-Dong},
  booktitle={2017 26th Wireless and Optical Communication Conference (WOCC)},
  pages={1--5},
  year={2017},
  organization={IEEE}
}
@ARTICLE{8963964,
  author={Huynh-The, Thien and Hua, Cam-Hao and Pham, Quoc-Viet and Kim, Dong-Seong},
  journal={IEEE Communications Letters}, 
  title={MCNet: An Efficient CNN Architecture for Robust Automatic Modulation Classification}, 
  year={2020},
  volume={24},
  number={4},
  pages={811-815},
  keywords={Modulation;Convolution;Kernel;Feature extraction;Computer architecture;Network architecture;Computational modeling;Automatic modulation classification;deep learning;convolutional neural network;skip connection},
  doi={10.1109/LCOMM.2020.2968030}}

@INPROCEEDINGS{8322633,
  author={Hong, Dehua and Zhang, Zilong and Xu, Xiaodong},
  booktitle={2017 3rd IEEE International Conference on Computer and Communications (ICCC)}, 
  title={Automatic modulation classification using recurrent neural networks}, 
  year={2017},
  volume={},
  number={},
  pages={695-700},
  keywords={Logic gates;Training;Feature extraction;Modulation;Signal to noise ratio;Convolution;Recurrent neural networks;automatic modulation classification;recurrent neural network;convolutional neural network;gated recurrent unit},
  doi={10.1109/CompComm.2017.8322633}}
@ARTICLE{10423669,
  author={Zhao, Jikui and Wang, Huaxia and Peng, Shengliang and Yao, Yu-Dong},
  journal={IEEE Communications Letters}, 
  title={Meta Supervised Contrastive Learning for Few-Shot Open-Set Modulation Classification With Signal Constellation}, 
  year={2024},
  volume={28},
  number={4},
  pages={837-841},
  keywords={Self-supervised learning;Metalearning;Constellation diagram;Modulation;Training;Task analysis;Adaptation models;Few-shot learning;open-set classification;signal constellation;meta-learning;modulation classification},
  doi={10.1109/LCOMM.2024.3363630}}

@article{cai2022signal,
  title={Signal modulation classification based on the transformer network},
  author={Cai, Jingjing and Gan, Fengming and Cao, Xianghai and Liu, Wei},
  journal={IEEE Transactions on Cognitive Communications and Networking},
  volume={8},
  number={3},
  pages={1348--1357},
  year={2022},
  publisher={IEEE}
}
@INPROCEEDINGS{10139474,
  author={Samarkandi, Abdullah and Almarhabi, Alhussain and Alhazmi, Hatim and Yao, Yu-Dong},
  booktitle={2023 32nd Wireless and Optical Communications Conference (WOCC)}, 
  title={Combined Signal Representations for Modulation Classification Using Deep Learning: Ambiguity Function, Constellation Diagram, and Eye Diagram}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  keywords={Deep learning;Wireless communication;Constellation diagram;Quadrature amplitude modulation;Image representation;Optical fiber communication;Classification algorithms;Spectrum awareness;deep learning;modulation classification;constellation diagram;eye diagram;ambiguity function;quadrature amplitude modulation (QAM)},
  doi={10.1109/WOCC58016.2023.10139474}}
@article{kong2023transformer,
  title={A transformer-based contrastive semi-supervised learning framework for automatic modulation recognition},
  author={Kong, Weisi and Jiao, Xun and Xu, Yuhua and Zhang, Bolin and Yang, Qinghai},
  journal={IEEE Transactions on Cognitive Communications and Networking},
  year={2023},
  publisher={IEEE}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{graves2012long,
  title={Long short-term memory},
  author={Graves, Alex and Graves, Alex},
  journal={Supervised sequence labelling with recurrent neural networks},
  pages={37--45},
  year={2012},
  publisher={Springer}
}
@article{gao2023moe,
  title={Moe-amc: Enhancing automatic modulation classification performance using mixture-of-experts},
  author={Gao, Jiaxin and Cao, Qinglong and Chen, Yuntian},
  journal={arXiv preprint arXiv:2312.02298},
  year={2023}
}
@article{jafarigol2025ai,
  title={AI/ML-Based Automatic Modulation Recognition: Recent Trends and Future Possibilities},
  author={Jafarigol, Elaheh and Alaghband, Behnoud and Gilanpour, Azadeh and Hosseinipoor, Saeid and Mirmozafari, Mirhamed},
  journal={arXiv preprint arXiv:2502.05315},
  year={2025}
}
@article{AZZOUZ199555,
title = {Automatic identification of digital modulation types},
journal = {Signal Processing},
volume = {47},
number = {1},
pages = {55-69},
year = {1995},
issn = {0165-1684},
doi = {https://doi.org/10.1016/0165-1684(95)00099-2},
url = {https://www.sciencedirect.com/science/article/pii/0165168495000992},
author = {E.E. Azzouz and A.K. Nandi},
keywords = {Digital modulation, Modulation identification, Signal classification},
abstract = {In both covert and overt operations, modulation identification plays an important role. In communication intelligence (COMINT) applications the main objective is the perfect monitoring of the intercepted signals and one of the parameters that affect the perfect monitoring is the modulation type of the intercepted signal. In this paper, a set of decision criteria for identifying different types of digital modulation is developed. Also, all the key features used in the identification algorithm are calculated using the conventional signal processing methods. Computer simulations for different types of band-limited digitally modulated signals corrupted by band-limited Gaussian noise have been carried out. Expressions for the instantaneous amplitude, and phase of different types of digitally modulated signals are derived. Also, two software solutions for estimating the instantaneous phase in the weak segments of a signal are introduced and analyzed. Finally, it is found that all modulation types of interest have been classified with success rate ≥90% at SNR = 10 dB.
Zusammenfassung
Sowohl in verdecktem, als auch in offenem Betrieb spielt die Identifikation von Modulationen eine wichtige Rolle. In Anwendungen der Kommunikationsüberwachung (COMINT) besteht die Hauptaufgabe im perfektenÜberwachen der aufgefangenen Signale und einer der Parameter, die die perfekteÜberwachung beeinflussen, ist der Modulationstyp des aufgefangenen Signals. In dieser Abreit wird ein Satz von Entscheidungskriterien zur Identifikation verschiedener digitaler Modulationstypen entwickelt. Auβerdem werden alle grundlegenden Eigenschaften, die im Identifikationsalgorithmus benutzt werden, mit Hilfe von konventionellen Signalverarbeitungsmethoden berechnet. Rechnersimulationen mit verschiedenen Typen bandbegrenzter digitalmodulierter Signale, die durch bandbegrenztes Gauβsches Rauschen gestört wurden, wurden durchgeführt. Ausdrücke für die Momentan-amplitude und -phase verschiedener Typen digital modulierter Signale werden hergeleitet. Zusätzlich werden zwei Softwarelösungen für die Schätzung der Momentanphase in abgeschwächten Signalsegmenten eingeführt und analysiert. Schlieβlich wird gefunden, daβ alle interessanten Modulationstypen mit einer Erfolgsrate ≥90% bei einem SNR = 10 dB klassifiziert wurden.
Résumé
L'identification de modulation joue un roˆle important aussi bien dans les opérations secrètes que les opérations publiques. Dans les applications d'intelligence des communications (INTCOM), l'objectif principal est l'observation parfaite des signaux interceptés et l'un des paramètres qui affecte cette observation parfaite est le type de modulation du signal intercepté. Dans cet article, on développe un ensemble de critères de décision pour identifier différents types de modulation numérique. De plus, toutes les caractéristiques-clés utilisées dans l'algorithme sont calculées en utilisant des méthodes de traitement du signal conventionnelles. Des simulations ontétéfaitesàl'ordinateur pour différents types de signaux modulés numériquement etàbande limitée, corrompus par du bruit blanc gaussienàbande limitée. On dérive des expressions pour l'amplitude instantanée et la phase de différents types de signaux modulés numériquement. En outre, deux solutions logicielles pour l'estimation de la phase instantanée dans les segments faibles d'un signal sont introduites et analysées. Enfin, on verra que tous les types de modulation qui sont intéressants ici ontétéclassés avec un taux de succes ≥90% pour un SNR = 10 dB.}
}
@article{wang2023meditab,
  title={MediTab: scaling medical tabular data predictors via data consolidation, enrichment, and refinement},
  author={Wang, Zifeng and Gao, Chufan and Xiao, Cao and Sun, Jimeng},
  journal={arXiv preprint arXiv:2305.12081},
  year={2023}
}

@inproceedings{faysal2024nmformer,
  title={NMformer: A Transformer for Noisy Modulation Classification in Wireless Communication},
  author={Faysal, Atik and Rostami, Mohammad and Roshan, Reihaneh Gh and Wang, Huaxia and Muralidhar, Nikhil},
  booktitle={2024 33rd Wireless and Optical Communications Conference (WOCC)},
  pages={103--108},
  year={2024},
  organization={IEEE}
}

@article{faysal2025denomae,
  title={DenoMAE: A Multimodal Autoencoder for Denoising Modulation Signals},
  author={Faysal, Atik and Boushine, Taha and Rostami, Mohammad and Roshan, Reihaneh Gh and Wang, Huaxia and Muralidhar, Nikhil and Sahoo, Avimanyu and Yao, Yu-Dong},
  journal={arXiv preprint arXiv:2501.11538},
  year={2025}
}

@misc{faysal2025denomae20improvingdenoisingmasked,
      title={DenoMAE2.0: Improving Denoising Masked Autoencoders by Classifying Local Patches}, 
      author={Atik Faysal and Mohammad Rostami and Taha Boushine and Reihaneh Gh. Roshan and Huaxia Wang and Nikhil Muralidhar},
      year={2025},
      eprint={2502.18202},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2502.18202}, 
}
@misc{deepseekai2025deepseekr1incentivizingreasoningcapability,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI and Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and Z. F. Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and J. L. Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and R. J. Chen and R. L. Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and S. S. Li and Shuang Zhou and Shaoqing Wu and Shengfeng Ye and Tao Yun and Tian Pei and Tianyu Sun and T. Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and W. L. Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and X. Q. Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and Y. K. Li and Y. Q. Wang and Y. X. Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yuan Ou and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yunfan Xiong and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Y. X. Zhu and Yanhong Xu and Yanping Huang and Yaohui Li and Yi Zheng and Yuchen Zhu and Yunxian Ma and Ying Tang and Yukun Zha and Yuting Yan and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhicheng Ma and Zhigang Yan and Zhiyu Wu and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Zizheng Pan and Zhen Huang and Zhipeng Xu and Zhongyu Zhang and Zhen Zhang},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}